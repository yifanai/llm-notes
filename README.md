# llm-notes: a curated set of notes, blogs, videos, papers, etc. on large language models

## Inference Optimization
- [Large Transformer Model Inference Optimization](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/). Lilian Weng. Jan 10, 2023.
- [Optimizing your LLM in production](https://huggingface.co/blog/optimize-llm). Hugging Face. Sep 15, 2023.
- [LLM Inference Performance Engineering: Best Practices](https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices). Databricks. Oct 12, 2023.
- [SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models](https://hanlab.mit.edu/projects/smoothquant). Xiao et al. Nov, 2022.
- [AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration](https://hanlab.mit.edu/projects/awq). Lin et al. Jun, 2023.
- [Efficient Streaming Language Models with Attention Sinks](https://hanlab.mit.edu/projects/streamingllm). Xiao et al. Sep, 2023.
- Video: [Flash Attention 2.0 with Tri Dao (author)! | Discord server talks](https://www.youtube.com/watch?v=IoMSGuiwV3g). Jul 21, 2023.
- Video: [Fast LLM Serving with vLLM and PagedAttention](https://www.youtube.com/watch?v=5ZlavKF_98U). Oct 12, 2023.
- Video: [Exploring the Latency/Throughput & Cost Space for LLM Inference by TimotheÃÅe Lacroix](https://www.youtube.com/watch?v=mYRqvB1_gRk). Oct 25, 2023.